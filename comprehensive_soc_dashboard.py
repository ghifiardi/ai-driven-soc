#!/usr/bin/env python3
"""
Comprehensive SOC Dashboard with Multi-Page Interface
Monitor all agents and scenarios in real-time with integrated feedback interface
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import json
import requests
from google.cloud import bigquery, pubsub_v1
import os

# Optional TI client (AbuseIPDB) for on-demand enrichment
try:
    import ti_abuseipdb
except Exception:
    ti_abuseipdb = None

# Multi-page configuration
PAGES = {
    "Overview": "overview_page",
    "Feedback": "feedback_page",
    "Analytics": "analytics_page"
}

# Page configuration
st.set_page_config(
    page_title="Comprehensive SOC Dashboard",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    # Sidebar Navigation
    st.sidebar.title("ğŸ“Š Dashboard Navigation")
    selected_page = st.sidebar.selectbox(
        "Select Dashboard Section",
        list(PAGES.keys()),
        key="page_selector"
    )

    # System Status (shown on all pages)
    st.sidebar.title("ğŸ“Š System Status")

    # Services Status
    st.sidebar.subheader("ğŸ”§ Services")
    ada_status = get_ada_status()
    cla_status = get_cla_status()

    if ada_status:
        st.sidebar.success(f"âœ… ADA: {ada_status.get('status', 'Unknown')}")
        st.sidebar.info(f"ğŸ“Š Predictions: {ada_status.get('predictions_count', 0)}")
        st.sidebar.info(f"ğŸ¯ Accuracy: {ada_status.get('accuracy', 0):.1%}")
    else:
        st.sidebar.error("âŒ ADA: Not responding")

    if cla_status:
        st.sidebar.success(f"âœ… CLA: {cla_status.get('status', 'Unknown')}")
        st.sidebar.info(f"ğŸ¤– Model: {cla_status.get('model_version', 'Unknown')}")
    else:
        st.sidebar.error("âŒ CLA: Not responding")

    # Pub/Sub Status
    st.sidebar.subheader("ğŸ“¡ Pub/Sub Topics")
    pubsub_status = get_pubsub_status()
    for topic, status in pubsub_status.items():
        if status == "Active":
            st.sidebar.success(f"âœ… {topic}")
        else:
            st.sidebar.error(f"âŒ {topic}")

    # Dashboard URLs
    st.sidebar.subheader("ğŸ”— Dashboard Links")
    st.sidebar.markdown("""
    - [Production CLA Dashboard](http://10.45.254.19:8504)
    - [Enhanced TAA Dashboard](http://10.45.254.19:8533)
    - [Simple TAA Dashboard](http://10.45.254.19:8534)
    - [TAA-CRA Integration](http://10.45.254.19:8531)
    """)

    # Page routing
    if selected_page == "Overview":
        overview_page()
    elif selected_page == "Feedback":
        feedback_page()
    elif selected_page == "Analytics":
        analytics_page()

def overview_page():
    """Main overview page with system status and metrics"""
    st.title("ğŸ›¡ï¸ Comprehensive SOC Dashboard")
    st.markdown("Real-time monitoring of all SOC agents and threat scenarios")

    # Main Content
    col1, col2, col3, col4 = st.columns(4)

    # Get real data for metrics
    df = get_bigquery_data()
    total_alerts = len(df) if not df.empty else 0
    anomaly_count = len(df[df['classification'] == 'anomaly']) if not df.empty else 0

    with col1:
        st.metric("ğŸ›¡ï¸ Total Agents", "4", "ADA, TAA, CLA, CRA")

    with col2:
        st.metric("âš¡ Active Services", "3", "ADA, CLA, TAA")

    with col3:
        st.metric("ğŸ“Š Alerts Processed (24h)", total_alerts)

    with col4:
        accuracy = ada_status.get('accuracy', 0) if ada_status else 0
        st.metric("ğŸ¯ System Accuracy", f"{accuracy:.1%}" if accuracy > 0 else "No feedback yet")

    # Threat Scenarios Section
    st.header("ğŸ¯ Threat Scenarios Status")

    scenarios_df = create_threat_scenarios()

    # Scenarios Overview
    col1, col2 = st.columns(2)

    with col1:
        # Severity Distribution
        if not scenarios_df.empty and 'severity' in scenarios_df.columns:
            severity_counts = scenarios_df['severity'].value_counts()
            if not severity_counts.empty:
                fig = px.pie(
                    values=severity_counts.values,
                    names=severity_counts.index,
                    title="Threat Severity Distribution",
                    color_discrete_map={
                        'CRITICAL': '#FF0000',
                        'HIGH': '#FF6600',
                        'MEDIUM': '#FFCC00',
                        'LOW': '#00CC00'
                    }
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No severity data available")
        else:
            st.info("No threat scenario data available")

    with col2:
        # Status Distribution
        if not scenarios_df.empty and 'status' in scenarios_df.columns:
            status_counts = scenarios_df['status'].value_counts()
            if not status_counts.empty:
                fig = px.bar(
                    x=status_counts.index,
                    y=status_counts.values,
                    title="Threat Status Distribution",
                    color=status_counts.values,
                    color_continuous_scale="RdYlGn_r"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No status data available")
        else:
            st.info("No threat scenario data available")

    # Detailed Scenarios Table
    st.subheader("ğŸ“‹ Detailed Threat Scenarios")

    # Color code severity
    def color_severity(val):
        if val == 'CRITICAL':
            return 'background-color: #FF0000; color: white'
        elif val == 'HIGH':
            return 'background-color: #FF6600; color: white'
        elif val == 'MEDIUM':
            return 'background-color: #FFCC00; color: black'
        elif val == 'LOW':
            return 'background-color: #00CC00; color: white'
        return ''

    # Color code status
    def color_status(val):
        if val == 'Contained':
            return 'background-color: #00CC00; color: white'
        elif val == 'Detected':
            return 'background-color: #FF6600; color: white'
        elif val == 'Investigation':
            return 'background-color: #FFCC00; color: black'
        elif val == 'Monitoring':
            return 'background-color: #0066CC; color: white'
        elif val == 'Blocked':
            return 'background-color: #00CC00; color: white'
        elif val == 'Mitigation':
            return 'background-color: #FF0000; color: white'
        elif val == 'Cleared':
            return 'background-color: #00CC00; color: white'
        return ''

    styled_df = scenarios_df.style.applymap(color_severity, subset=['severity']).applymap(color_status, subset=['status'])
    st.dataframe(styled_df, use_container_width=True)

    # Real-time Data Section
    st.header("ğŸ“Š Real-time Data Analysis")

    df = get_bigquery_data()

    if not df.empty:
        col1, col2 = st.columns(2)

        with col1:
            # Classification Distribution
            if 'classification' in df.columns:
                classification_counts = df['classification'].value_counts()
                fig = px.pie(
                    values=classification_counts.values,
                    names=classification_counts.index,
                    title="Alert Classification Distribution"
                )
                st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Confidence Distribution
            if 'confidence_score' in df.columns:
                fig = px.histogram(
                    df,
                    x='confidence_score',
                    nbins=20,
                    title="Confidence Score Distribution"
                )
                st.plotly_chart(fig, use_container_width=True)

        # Recent alerts table
        st.subheader("ğŸ“‹ Recent Alerts")

        # Format the dataframe for display
        display_df = df.copy()
        if 'timestamp' in display_df.columns:
            display_df['timestamp'] = pd.to_datetime(display_df['timestamp'])
            display_df['timestamp'] = display_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')

        # Select available columns for display
        available_columns = []
        for col in ['alert_id', 'confidence_score', 'classification', 'timestamp', 'is_anomaly']:
            if col in display_df.columns:
                available_columns.append(col)

        if available_columns:
            st.dataframe(
                display_df[available_columns].head(10),
                use_container_width=True
            )
    else:
        st.warning("No real-time data available from BigQuery")

    # Workflow Status
    st.header("ğŸ”„ Multi-Agent Workflow Status")

    workflow_status = {
        "ADA (Anomaly Detection)": "âœ… Active",
        "TAA (Triage & Analysis)": "âœ… Active",
        "CLA (Continuous Learning)": "âœ… Active",
        "CRA (Containment Response)": "âš ï¸ Standby"
    }

    col1, col2 = st.columns(2)

    with col1:
        for agent, status in list(workflow_status.items())[:2]:
            st.markdown(f"**{agent}:** {status}")

    with col2:
        for agent, status in list(workflow_status.items())[2:]:
            st.markdown(f"**{agent}:** {status}")

    # Performance Metrics
    st.header("ğŸ“ˆ Performance Metrics")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("âš¡ Avg Response Time", "3.2s", "TAA Flash 2.5")

    with col2:
        accuracy = ada_status.get('accuracy', 0) if ada_status else 0
        st.metric("ğŸ¯ System Accuracy", f"{accuracy:.1%}" if accuracy > 0 else "No feedback yet")

    with col3:
        total_alerts = len(df) if not df.empty else 0
        st.metric("ğŸ“Š Alerts (24h)", total_alerts)

    with col4:
        detection_rate = len(df[df['classification'] == 'anomaly']) / max(len(df), 1) * 100 if not df.empty else 0
        st.metric("ğŸ” Detection Rate", f"{detection_rate:.1f}%")

    # Accuracy Trend (if we have historical data)
    st.subheader("ğŸ“ˆ Accuracy Trend (7 days)")

    try:
        client = bigquery.Client(project="chronicle-dev-2be9")
        trend_query = """
        SELECT
            DATE(timestamp) as date,
            AVG(CASE WHEN is_true_positive = true THEN 1.0 ELSE 0.0 END) as accuracy,
            COUNT(*) as feedback_count
        FROM `chronicle-dev-2be9.soc_data.feedback`
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
        GROUP BY DATE(timestamp)
        ORDER BY date
        """

        trend_df = client.query(trend_query).to_dataframe()

        if not trend_df.empty:
            fig = px.line(
                trend_df,
                x='date',
                y='accuracy',
                title="Accuracy Trend Over Time",
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No historical accuracy data available yet")

    except Exception as e:
        st.warning(f"Could not load accuracy trend: {e}")

    # Advanced Feedback Controls
    st.subheader("ğŸ›ï¸ Advanced Feedback Controls")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ”„ Generate Sophisticated Feedback", type="primary"):
            try:
                # Import and run the advanced feedback monitor
                import subprocess
                result = subprocess.run([
                    "python3", "/home/app/advanced_feedback_monitor.py"
                ], capture_output=True, text=True, timeout=60)

                if result.returncode == 0:
                    st.success("âœ… Sophisticated feedback generated successfully!")
                    st.code(result.stdout[-500:])  # Show last 500 chars
                else:
                    st.error("âŒ Error generating feedback")
                    st.code(result.stderr[-500:])

            except Exception as e:
                st.error(f"Error running feedback generation: {e}")

    with col2:
        if st.button("ğŸ“Š Refresh Accuracy Metrics"):
            st.rerun()

    # Footer
    st.markdown("---")
    st.markdown(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.markdown("ğŸ›¡ï¸ Enhanced SOC with Google Flash 2.5 TAA Integration")

def feedback_page():
    """Feedback submission interface"""
    st.title("ğŸ“ SOC Analyst Feedback Dashboard")
    st.markdown("Review alerts and provide feedback for continuous learning")

    # Get alerts
    alerts_df = get_unreviewed_alerts()

    if alerts_df.empty:
        st.info("No alerts available for review")
        return

    st.subheader("ğŸ“‹ Alerts for Review")

    # Display alerts in a table
    for i, (_, alert) in enumerate(alerts_df.iterrows()):
        with st.expander(f"Alert {i+1}: {alert['alert_id'][:20]}..."):
            col1, col2 = st.columns(2)

            with col1:
                st.write(f"**Classification:** {alert['classification']}")
                st.write(f"**Confidence:** {alert['confidence_score']:.3f}")
                st.write(f"**Timestamp:** {alert['timestamp']}")

            with col2:
                st.write("**Your Assessment:**")

                # Feedback form
                with st.form(f"feedback_{i}"):
                    is_true_positive = st.radio(
                        "Is this a true positive?",
                        ["True Positive", "False Positive"],
                        key=f"tp_{i}"
                    )

                    analyst_confidence = st.slider(
                        "Your confidence in this assessment",
                        0.0, 1.0, 0.8, 0.1,
                        key=f"conf_{i}"
                    )

                    comments = st.text_area(
                        "Comments (optional)",
                        placeholder="Add any additional context or reasoning...",
                        key=f"comments_{i}"
                    )

                    submitted = st.form_submit_button("Submit Feedback")

                    if submitted:
                        success, message = submit_feedback(
                            alert['alert_id'],
                            is_true_positive == "True Positive",
                            analyst_confidence,
                            comments
                        )

                        if success:
                            st.success(message)
                            st.rerun()
                        else:
                            st.error(message)

    # Show recent feedback submissions
    st.subheader("ğŸ“ Recent Feedback Submissions")

    try:
        client = bigquery.Client(project="chronicle-dev-2be9")
        feedback_query = """
        SELECT
            alert_id,
            is_true_positive,
            confidence,
            analyst_comments,
            timestamp
        FROM `chronicle-dev-2be9.soc_data.feedback`
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
        ORDER BY timestamp DESC
        LIMIT 10
        """

        feedback_df = client.query(feedback_query).to_dataframe()

        if not feedback_df.empty:
            st.dataframe(feedback_df)
        else:
            st.info("No recent feedback submissions")

    except Exception as e:
        st.error(f"Error fetching feedback: {e}")

def analytics_page():
    """Advanced analytics and monitoring"""
    st.title("ğŸ“Š SOC Analytics Dashboard")
    st.markdown("Advanced analytics and performance monitoring")

    # Get data for analytics
    df = get_bigquery_data()

    if df.empty:
        st.warning("No data available for analytics")
        return

    st.header("ğŸ“ˆ Advanced Analytics")

    # Time-based analysis
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Classification Over Time")
        if 'timestamp' in df.columns and 'classification' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            time_series = df.groupby([df['timestamp'].dt.date, 'classification']).size().unstack(fill_value=0)
            fig = px.line(time_series, title="Alert Classification Over Time")
            st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Confidence vs Classification")
        if 'confidence_score' in df.columns and 'classification' in df.columns:
            fig = px.scatter(df, x='confidence_score', y='classification',
                           color='classification', title="Confidence Distribution by Classification")
            st.plotly_chart(fig, use_container_width=True)

    # Correlation analysis
    st.subheader("ğŸ”— Correlation Analysis")

    if len(df) > 10:  # Only show if we have enough data
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 1:
            correlation_matrix = df[numeric_cols].corr()
            fig = px.imshow(correlation_matrix, title="Feature Correlation Matrix")
            st.plotly_chart(fig, use_container_width=True)

    # Performance insights
    st.subheader("ğŸ¯ Performance Insights")

    if not df.empty:
        total_alerts = len(df)
        anomalies = len(df[df['classification'] == 'anomaly'])
        benign = len(df[df['classification'] == 'benign'])

        st.markdown(f"""
        **Dataset Summary:**
        - **Total Alerts:** {total_alerts}
        - **Anomalies Detected:** {anomalies} ({anomalies/total_alerts*100:.1f}%)
        - **Benign Classifications:** {benign} ({benign/total_alerts*100:.1f}%)

        **Classification Distribution:**
        """)

        classification_dist = df['classification'].value_counts()
        for cls, count in classification_dist.items():
            st.markdown(f"- **{cls.title()}:** {count} alerts ({count/total_alerts*100:.1f}%)")

        if 'confidence_score' in df.columns:
            avg_confidence = df['confidence_score'].mean()
            st.markdown(f"""
            **Confidence Analysis:**
            - **Average Confidence:** {avg_confidence:.3f}
            - **High Confidence (>0.8):** {len(df[df['confidence_score'] > 0.8])} alerts
            - **Medium Confidence (0.5-0.8):** {len(df[(df['confidence_score'] >= 0.5) & (df['confidence_score'] <= 0.8)])} alerts
            - **Low Confidence (<0.5):** {len(df[df['confidence_score'] < 0.5])} alerts
            """)

    # Footer
    st.markdown("---")
    st.markdown(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.markdown("ğŸ“Š Advanced SOC Analytics Dashboard")

def get_ada_status():
    """Get ADA service status"""
    try:
        response = requests.get("http://localhost:8080/status", timeout=5)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return None

def get_cla_status():
    """Get CLA service status"""
    try:
        response = requests.get("http://localhost:8080/status", timeout=5)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return None

def get_bigquery_data():
    """Get data from BigQuery for analysis"""
    try:
        client = bigquery.Client(project="chronicle-dev-2be9")
        
        # Query for recent alerts
        query = """
        SELECT 
            alert_id,
            confidence_score,
            classification,
            timestamp,
            is_anomaly,
            raw_alert
        FROM `chronicle-dev-2be9.soc_data.processed_alerts`
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
        ORDER BY timestamp DESC
        LIMIT 50
        """
        
        df = client.query(query).to_dataframe()
        return df
    except Exception as e:
        st.error(f"Error fetching BigQuery data: {e}")
        return pd.DataFrame()

def get_pubsub_status():
    """Check Pub/Sub topics status"""
    try:
        publisher = pubsub_v1.PublisherClient()
        project_id = "chronicle-dev-2be9"
        
        topics = [
            "ada-alerts",
            "taa-feedback", 
            "containment-requests",
            "taa-reports"
        ]
        
        status = {}
        for topic_name in topics:
            topic_path = publisher.topic_path(project_id, topic_name)
            try:
                publisher.get_topic(request={"topic": topic_path})
                status[topic_name] = "Active"
            except:
                status[topic_name] = "Inactive"
        
        return status
    except:
        return {}

def create_threat_scenarios():
    """Get real threat scenarios from BigQuery processed alerts"""
    try:
        client = bigquery.Client(project="chronicle-dev-2be9")

        # Query for recent processed alerts to create threat scenarios
        query = """
        SELECT
            alert_id,
            confidence_score,
            classification,
            timestamp,
            is_anomaly,
            raw_alert
        FROM `chronicle-dev-2be9.soc_data.processed_alerts`
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
        ORDER BY timestamp DESC
        LIMIT 20
        """

        df = client.query(query).to_dataframe()

        if df.empty:
            # Fallback to sample data if no real data
            return create_sample_scenarios()

        scenarios = []
        for i, row in df.iterrows():
            # Extract information from raw_alert if available
            raw_alert = row.get('raw_alert', {})
            if isinstance(raw_alert, str):
                try:
                    raw_alert = json.loads(raw_alert)
                except:
                    raw_alert = {}

            # Determine scenario type based on classification and features
            classification = row.get('classification', 'unknown')
            confidence = row.get('confidence_score', 0)

            # Create scenario description
            src_ip = raw_alert.get('src_ip') or raw_alert.get('source_ip', 'Unknown')
            dst_ip = raw_alert.get('dst_ip') or raw_alert.get('dest_ip', 'Unknown')
            port = raw_alert.get('port', 'Unknown')
            protocol = raw_alert.get('protocol', 'Unknown').upper()

            if classification == 'anomaly':
                if port in [22, 23, 3389] or 'SSH' in protocol or 'RDP' in protocol:
                    scenario_type = "Brute Force Attack"
                    description = f"Failed login attempts from {src_ip} to {dst_ip}:{port}"
                elif 'HTTP' in protocol and confidence > 0.8:
                    scenario_type = "Data Exfiltration"
                    description = f"Large HTTP transfer from {src_ip} to {dst_ip}"
                elif confidence > 0.9:
                    scenario_type = "Malware C2"
                    description = f"High confidence anomaly from {src_ip}"
                else:
                    scenario_type = "Suspicious Activity"
                    description = f"Anomalous traffic from {src_ip} to {dst_ip}"
            elif classification == 'benign':
                scenario_type = "Normal Traffic"
                description = f"Normal {protocol} traffic from {src_ip} to {dst_ip}"
            else:
                scenario_type = "Unknown Activity"
                description = f"Traffic from {src_ip} to {dst_ip}"

            # Determine severity and status
            severity = "CRITICAL" if confidence >= 0.9 else "HIGH" if confidence >= 0.7 else "MEDIUM" if confidence >= 0.5 else "LOW"

            # Determine status based on confidence and classification
            if classification == 'anomaly':
                status = "Detected"
            elif classification == 'benign':
                status = "Cleared"
            else:
                status = "Monitoring"

            scenarios.append({
                "scenario": scenario_type,
                "severity": severity,
                "confidence": confidence,
                "status": status,
                "timestamp": row.get('timestamp'),
                "description": description,
                "alert_id": row.get('alert_id')
            })

        return pd.DataFrame(scenarios)

    except Exception as e:
        st.error(f"Error fetching real threat scenarios: {e}")
        # Fallback to sample data
        return create_sample_scenarios()

def create_sample_scenarios():
    """Fallback sample scenarios if BigQuery fails"""
    scenarios = [
        {
            "scenario": "No Real Data Available",
            "severity": "LOW",
            "confidence": 0.0,
            "status": "Monitoring",
            "timestamp": datetime.now(),
            "description": "Unable to fetch real data from BigQuery. Check database connection."
        }
    ]
    return pd.DataFrame(scenarios)

def main():
    st.title("ğŸ›¡ï¸ Comprehensive SOC Dashboard")
    st.markdown("Real-time monitoring of all SOC agents and threat scenarios")
    
    # Sidebar
    st.sidebar.title("ğŸ”§ System Status")
    
    # Service Status
    st.sidebar.subheader("ğŸ“¡ Services")
    ada_status = get_ada_status()
    cla_status = get_cla_status()
    
    if ada_status:
        st.sidebar.success(f"âœ… ADA: {ada_status.get('status', 'Unknown')}")
        st.sidebar.info(f"ğŸ“Š Predictions: {ada_status.get('predictions_count', 0)}")
        st.sidebar.info(f"ğŸ¯ Accuracy: {ada_status.get('accuracy', 0):.1%}")
    else:
        st.sidebar.error("âŒ ADA: Not responding")
    
    if cla_status:
        st.sidebar.success(f"âœ… CLA: {cla_status.get('status', 'Unknown')}")
        st.sidebar.info(f"ğŸ¤– Model: {cla_status.get('model_version', 'Unknown')}")
    else:
        st.sidebar.error("âŒ CLA: Not responding")
    
    # Pub/Sub Status
    st.sidebar.subheader("ğŸ“¡ Pub/Sub Topics")
    pubsub_status = get_pubsub_status()
    for topic, status in pubsub_status.items():
        if status == "Active":
            st.sidebar.success(f"âœ… {topic}")
        else:
            st.sidebar.error(f"âŒ {topic}")
    
    # Dashboard URLs
    st.sidebar.subheader("ğŸ”— Dashboard Links")
    st.sidebar.markdown("""
    - [Production CLA Dashboard](http://10.45.254.19:8504)
    - [Enhanced TAA Dashboard](http://10.45.254.19:8533)
    - [Simple TAA Dashboard](http://10.45.254.19:8534)
    - [TAA-CRA Integration](http://10.45.254.19:8531)
    """)
    
    # Main Content
    col1, col2, col3, col4 = st.columns(4)
    
    # Get real data for metrics
    df = get_bigquery_data()
    total_alerts = len(df) if not df.empty else 0
    anomaly_count = len(df[df['classification'] == 'anomaly']) if not df.empty else 0

    with col1:
        st.metric("ğŸ›¡ï¸ Total Agents", "4", "ADA, TAA, CLA, CRA")

    with col2:
        st.metric("âš¡ Active Services", "3", "ADA, CLA, TAA")

    with col3:
        st.metric("ğŸ“Š Alerts Processed (24h)", total_alerts)

    with col4:
        accuracy = ada_status.get('accuracy', 0) if ada_status else 0
        st.metric("ğŸ¯ System Accuracy", f"{accuracy:.1%}" if accuracy > 0 else "No feedback yet")
    
    # Threat Scenarios Section
    st.header("ğŸ¯ Threat Scenarios Status")
    
    scenarios_df = create_threat_scenarios()
    
    # Scenarios Overview
    col1, col2 = st.columns(2)

    with col1:
        # Severity Distribution
        if not scenarios_df.empty and 'severity' in scenarios_df.columns:
            severity_counts = scenarios_df['severity'].value_counts()
            if not severity_counts.empty:
                fig = px.pie(
                    values=severity_counts.values,
                    names=severity_counts.index,
                    title="Threat Severity Distribution",
                    color_discrete_map={
                        'CRITICAL': '#FF0000',
                        'HIGH': '#FF6600',
                        'MEDIUM': '#FFCC00',
                        'LOW': '#00CC00'
                    }
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No severity data available")
        else:
            st.info("No threat scenario data available")

    with col2:
        # Status Distribution
        if not scenarios_df.empty and 'status' in scenarios_df.columns:
            status_counts = scenarios_df['status'].value_counts()
            if not status_counts.empty:
                fig = px.bar(
                    x=status_counts.index,
                    y=status_counts.values,
                    title="Threat Status Distribution",
                    color=status_counts.values,
                    color_continuous_scale="RdYlGn_r"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No status data available")
        else:
            st.info("No threat scenario data available")
    
    # Detailed Scenarios Table
    st.subheader("ğŸ“‹ Detailed Threat Scenarios")
    
    # Color code severity
    def color_severity(val):
        if val == 'CRITICAL':
            return 'background-color: #FF0000; color: white'
        elif val == 'HIGH':
            return 'background-color: #FF6600; color: white'
        elif val == 'MEDIUM':
            return 'background-color: #FFCC00; color: black'
        elif val == 'LOW':
            return 'background-color: #00CC00; color: white'
        return ''
    
    # Color code status
    def color_status(val):
        if val == 'Contained':
            return 'background-color: #00CC00; color: white'
        elif val == 'Detected':
            return 'background-color: #FF6600; color: white'
        elif val == 'Investigation':
            return 'background-color: #FFCC00; color: black'
        elif val == 'Monitoring':
            return 'background-color: #0066CC; color: white'
        elif val == 'Blocked':
            return 'background-color: #00CC00; color: white'
        elif val == 'Mitigation':
            return 'background-color: #FF0000; color: white'
        elif val == 'Cleared':
            return 'background-color: #00CC00; color: white'
        return ''
    
    styled_df = scenarios_df.style.applymap(color_severity, subset=['severity']).applymap(color_status, subset=['status'])
    st.dataframe(styled_df, use_container_width=True)
    
    # Real-time Data Section
    st.header("ğŸ“Š Real-time Data Analysis")
    
    df = get_bigquery_data()
    
    if not df.empty:
        col1, col2 = st.columns(2)
        
        with col1:
            # Classification Distribution
            if 'classification' in df.columns:
                classification_counts = df['classification'].value_counts()
                fig = px.pie(
                    values=classification_counts.values,
                    names=classification_counts.index,
                    title="Alert Classification Distribution"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Confidence Distribution
            if 'confidence_score' in df.columns:
                fig = px.histogram(
                    df, 
                    x='confidence_score', 
                    nbins=20,
                    title="Confidence Score Distribution"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # Alerts Review Table (similar to screenshot)
        st.subheader("ğŸ“‹ All Agents Alerts Review")
        st.caption("Unified view combining ADA outputs with TAA insights when available")
        
        def build_alerts_review(source_df: pd.DataFrame) -> pd.DataFrame:
            rows = []
            for _, r in source_df.iterrows():
                raw_val = r.get('raw_alert')
                raw_obj = None
                if isinstance(raw_val, str):
                    try:
                        raw_obj = json.loads(raw_val)
                    except Exception:
                        raw_obj = None
                elif isinstance(raw_val, dict):
                    raw_obj = raw_val
                
                # Try to find embedded TAA result if present (support multiple shapes)
                taa_result = None
                if isinstance(raw_obj, dict):
                    taa_result = (
                        raw_obj.get('taa_result')
                        or raw_obj.get('llm_result')
                        or raw_obj.get('taa_analysis_result')
                        or raw_obj.get('taa_analysis')
                    )
                    # Some records store TAA under nested keys
                    if not isinstance(taa_result, dict):
                        possible_nested = raw_obj.get('taa') or raw_obj.get('analysis')
                        if isinstance(possible_nested, dict) and isinstance(possible_nested.get('result'), dict):
                            taa_result = possible_nested['result']
                
                def get_safe(d: dict, *keys, default=None):
                    if not isinstance(d, dict):
                        return default
                    cur = d
                    for k in keys:
                        if not isinstance(cur, dict) or k not in cur:
                            return default
                        cur = cur[k]
                    return cur
                
                cra_action = get_safe(raw_obj, 'containment_request', 'action')
                cra_success = get_safe(raw_obj, 'containment_request', 'success')
                ada_reasoning = raw_obj.get('ada_reasoning') if isinstance(raw_obj, dict) else None
                taa_conf = get_safe(taa_result or {}, 'confidence')
                taa_sev = get_safe(taa_result or {}, 'severity')
                taa_valid = get_safe(taa_result or {}, 'is_true_positive')
                taa_reason = get_safe(taa_result or {}, 'reasoning')
                
                # Heuristic fallbacks to reduce None values
                ada_class = (r.get('classification') or '').lower()
                ada_conf = r.get('confidence_score')
                # ADA Valid fallback from class
                ada_valid_fallback = None if pd.isna(r.get('is_anomaly')) else bool(r.get('is_anomaly'))
                if ada_valid_fallback is None and ada_class:
                    ada_valid_fallback = (ada_class == 'anomaly')
                # TAA fallbacks when not present
                if taa_conf is None:
                    taa_conf = ada_conf
                if not taa_sev:
                    if isinstance(ada_conf, (int, float)):
                        if ada_conf >= 0.8:
                            taa_sev = 'high'
                        elif ada_conf >= 0.5:
                            taa_sev = 'medium'
                        else:
                            taa_sev = 'low'
                    else:
                        taa_sev = 'medium'
                if taa_valid is None and ada_valid_fallback is not None:
                    taa_valid = ada_valid_fallback
                if not ada_reasoning:
                    ada_reasoning = f"ADA classified as '{ada_class}' with confidence {ada_conf}; no detailed reasoning recorded."
                if not taa_reason:
                    taa_reason = f"Heuristic triage based on ADA output: severity {taa_sev}, confidence {taa_conf}."
                
                rows.append({
                    'Alarm ID': r.get('alert_id'),
                    'ADA Case Class': r.get('classification'),
                    'CRA Action Type': cra_action,
                    'ADA Confidence': r.get('confidence_score'),
                    'TAA Confidence': taa_conf,
                    'ADA Score': r.get('confidence_score'),
                    'TAA Severity': taa_sev,
                    # Handle pandas NA safely for ADA Valid
                    'ADA Valid': (None if pd.isna(r.get('is_anomaly')) else bool(r.get('is_anomaly'))),
                    'TAA Valid': taa_valid,
                    'CRA Success': cra_success,
                    'ADA Reasoning': ada_reasoning,
                    'TAA Reasoning': taa_reason,
                    'Timestamp': r.get('timestamp')
                })
            review_df = pd.DataFrame(rows)
            # Format timestamp
            if 'Timestamp' in review_df.columns:
                try:
                    review_df['Timestamp'] = pd.to_datetime(review_df['Timestamp']).dt.strftime('%Y-%m-%d %H:%M:%S')
                except Exception:
                    pass
            return review_df
        
        review_df = build_alerts_review(df)
        
        # Friendly display defaults
        display_defaults = {
            'CRA Action Type': 'None',
            'TAA Confidence': '-',
            'TAA Severity': 'None',
            'ADA Valid': '-',
            'TAA Valid': '-',
            'CRA Success': '-',
            'ADA Reasoning': 'None',
            'TAA Reasoning': 'None'
        }
        for col, default_val in display_defaults.items():
            if col in review_df.columns:
                review_df[col] = review_df[col].map(lambda v: default_val if pd.isna(v) or v is None else v)
        
        # Filters
        fcol1, fcol2, fcol3, fcol4 = st.columns(4)
        with fcol1:
            search_reason = st.text_input("Search in Reasoning", "")
        with fcol2:
            search_category = st.text_input("Search in Category", "")
        with fcol3:
            search_alarm = st.text_input("Search Alarm ID", "")
        with fcol4:
            st.button("Refresh Data")
        
        filtered_df = review_df.copy()
        if search_reason:
            mask = filtered_df['ADA Reasoning'].fillna("").str.contains(search_reason, case=False) | \
                   filtered_df['TAA Reasoning'].fillna("").str.contains(search_reason, case=False)
            filtered_df = filtered_df[mask]
        if search_category:
            mask = filtered_df['ADA Case Class'].fillna("").str.contains(search_category, case=False) | \
                   filtered_df['TAA Severity'].fillna("").str.contains(search_category, case=False)
            filtered_df = filtered_df[mask]
        if search_alarm:
            filtered_df = filtered_df[filtered_df['Alarm ID'].astype(str).str.contains(search_alarm, case=False)]
        
        # Selection controls
        st.markdown("\n")
        sel_col1, sel_col2 = st.columns(2)
        with sel_col1:
            selection_mode = st.radio("Selection Mode", ["Individual", "Batch"], horizontal=True)
        with sel_col2:
            rows_per_page = st.slider("Rows per page", 10, 1000, 50, step=10)
        
        display_cols = [
            'Alarm ID','ADA Case Class','CRA Action Type','ADA Confidence','TAA Confidence',
            'ADA Score','TAA Severity','ADA Valid','TAA Valid','CRA Success','ADA Reasoning','TAA Reasoning','Timestamp'
        ]
        table_df = filtered_df[display_cols].reset_index(drop=True)
        
        # Display table
        st.dataframe(
            table_df.head(rows_per_page),
            use_container_width=True,
            height=420
        )
        
        # Individual vs Batch selection
        id_list = table_df['Alarm ID'].dropna().astype(str).unique().tolist()
        if selection_mode == "Individual":
            selected_id = st.selectbox("Select an alert to view details", id_list)
            sel_row = filtered_df[filtered_df['Alarm ID'].astype(str) == selected_id].head(1)
            st.markdown("### ğŸ” Selected Alert Details")
            sel_payload = sel_row.to_dict(orient='records')[0] if not sel_row.empty else {}
            st.json(sel_payload)

            # Try to find richer TAA fields and TI from raw record if available
            raw_detail = {}
            try:
                # re-derive from original df row's raw_alert
                base_row = df[df['alert_id'].astype(str) == str(sel_payload.get('Alarm ID'))].head(1)
                if not base_row.empty:
                    raw_val = base_row.iloc[0].get('raw_alert')
                    if isinstance(raw_val, str):
                        import json as _json
                        try:
                            raw_detail = _json.loads(raw_val)
                        except Exception:
                            raw_detail = {}
                    elif isinstance(raw_val, dict):
                        raw_detail = raw_val
            except Exception:
                raw_detail = {}

            taa_block = None
            if isinstance(raw_detail, dict):
                taa_block = (
                    raw_detail.get('taa_result')
                    or raw_detail.get('llm_result')
                    or raw_detail.get('taa_analysis_result')
                    or raw_detail.get('taa_analysis')
                )
            ioc_results = {}
            if isinstance(taa_block, dict) and isinstance(taa_block.get('ioc_results'), dict):
                ioc_results = taa_block.get('ioc_results')
            elif isinstance(raw_detail, dict) and isinstance(raw_detail.get('ioc_results'), dict):
                ioc_results = raw_detail.get('ioc_results')

            top_factors = []
            if isinstance(taa_block, dict):
                tf = taa_block.get('top_factors') or []
                if isinstance(tf, list):
                    top_factors = tf
            mitre = []
            if isinstance(taa_block, dict):
                mt = taa_block.get('mitre_techniques') or []
                if isinstance(mt, list):
                    mitre = mt
            rec_actions = []
            if isinstance(taa_block, dict):
                ra = taa_block.get('recommended_actions') or []
                if isinstance(ra, list):
                    rec_actions = ra
            fused_risk = None
            if isinstance(taa_block, dict) and 'fused_risk_score' in taa_block:
                fused_risk = taa_block.get('fused_risk_score')

            # Deep Dive panel similar to reference screenshot
            with st.expander("ğŸ§­ Deep Dive - Multiple Aspects", expanded=True):
                dcol1, dcol2 = st.columns(2)
                with dcol1:
                    st.markdown("**Alarm ID**")
                    st.code(sel_payload.get('Alarm ID', '-'))
                    st.markdown("**ADA Case Class**")
                    st.code(sel_payload.get('ADA Case Class', '-'))
                    st.markdown("**ADA Confidence**")
                    st.code(str(sel_payload.get('ADA Confidence', '-')))
                    st.markdown("**ADA Score**")
                    st.code(str(sel_payload.get('ADA Score', '-')))
                    st.markdown("**ADA Valid**")
                    st.code(str(sel_payload.get('ADA Valid', '-')))
                with dcol2:
                    st.markdown("**TAA Confidence**")
                    st.code(str(sel_payload.get('TAA Confidence', '-')))
                    st.markdown("**TAA Severity**")
                    st.code(str(sel_payload.get('TAA Severity', '-')))
                    st.markdown("**TAA Valid**")
                    st.code(str(sel_payload.get('TAA Valid', '-')))
                    st.markdown("**CRA Action Type**")
                    st.code(str(sel_payload.get('CRA Action Type', '-')))
                    st.markdown("**CRA Success**")
                    st.code(str(sel_payload.get('CRA Success', '-')))

                # Enriched insights
                if fused_risk is not None:
                    st.markdown("**Fused Risk Score**")
                    st.code(str(fused_risk))
                if top_factors:
                    st.markdown("**Top Factors (ranked)**")
                    st.code("\n".join(f"- {f}" for f in top_factors))
                if mitre:
                    st.markdown("**Mapped MITRE Techniques**")
                    st.code(", ".join(mitre))
                if rec_actions:
                    st.markdown("**Recommended Actions**")
                    st.code("\n".join(f"- {a}" for a in rec_actions))

                st.markdown("**Case Class Recommendation**")
                rec = sel_payload.get('TAA Severity') or sel_payload.get('ADA Case Class') or 'unknown'
                st.code(str(rec))

                rcol1, rcol2 = st.columns(2)
                with rcol1:
                    st.markdown("**ADA Reasoning**")
                    st.code(sel_payload.get('ADA Reasoning', 'None'))
                with rcol2:
                    st.markdown("**TAA Reasoning**")
                    st.code(sel_payload.get('TAA Reasoning', 'None'))

                # Threat Intelligence section
                st.markdown("**Threat Intelligence (AbuseIPDB)**")
                if isinstance(ioc_results, dict) and 'abuseipdb' in ioc_results and isinstance(ioc_results['abuseipdb'], dict):
                    ab = ioc_results['abuseipdb']
                    for ip, payload in ab.items():
                        icol1, icol2, icol3 = st.columns(3)
                        with icol1:
                            st.markdown(f"IP: `{ip}`")
                            st.markdown(f"Score: `{payload.get('abuseConfidenceScore', '-')}`")
                        with icol2:
                            st.markdown(f"Reports: `{payload.get('totalReports', '-')}`")
                            st.markdown(f"Last Seen: `{payload.get('lastReportedAt', '-')}`")
                        with icol3:
                            st.markdown(f"ISP/Domain: `{payload.get('isp', '-')}` / `{payload.get('domain', '-')}`")
                            st.markdown(f"Whitelisted: `{payload.get('isWhitelisted', '-')}`")
                    with st.expander("Raw TI JSON"):
                        import json as _json
                        st.code(_json.dumps(ioc_results, indent=2))
                else:
                    # Attempt on-demand TI lookup if not present in data
                    if ti_abuseipdb and isinstance(raw_detail, dict):
                        ips = []
                        for k in ("src_ip","source_ip","dst_ip","dest_ip"):
                            v = raw_detail.get(k)
                            if isinstance(v, str) and v and v not in ips:
                                ips.append(v)
                        if ips:
                            ab = {}
                            for ip in ips:
                                try:
                                    ab[ip] = ti_abuseipdb.query_abuseipdb(ip)
                                except Exception:
                                    pass
                            if ab:
                                st.success("Live TI lookup performed (not persisted)")
                                for ip, payload in ab.items():
                                    icol1, icol2, icol3 = st.columns(3)
                                    with icol1:
                                        st.markdown(f"IP: `{ip}`")
                                        st.markdown(f"Score: `{payload.get('abuseConfidenceScore', '-')}`")
                                    with icol2:
                                        st.markdown(f"Reports: `{payload.get('totalReports', '-')}`")
                                        st.markdown(f"Last Seen: `{payload.get('lastReportedAt', '-')}`")
                                    with icol3:
                                        st.markdown(f"ISP/Domain: `{payload.get('isp', '-')}` / `{payload.get('domain', '-')}`")
                                        st.markdown(f"Whitelisted: `{payload.get('isWhitelisted', '-')}`")
                            else:
                                st.info("No TI available for this alert yet.")
                        else:
                            st.info("No TI available for this alert yet.")
                    else:
                        st.info("No TI available for this alert yet.")

                st.caption("Provide feedback in your existing feedback app; this view is read-only.")
        else:
            selected_ids = st.multiselect("Select alerts (batch)", id_list, default=id_list[:10])
            batch_rows = filtered_df[filtered_df['Alarm ID'].astype(str).isin(selected_ids)]
            st.markdown(f"### ğŸ“¦ Batch Selection ({len(batch_rows)} alerts)")
            st.dataframe(batch_rows[display_cols], use_container_width=True, height=300)
    else:
        st.warning("No real-time data available from BigQuery")
    
    # Workflow Status
    st.header("ğŸ”„ Multi-Agent Workflow Status")
    
    workflow_status = {
        "ADA (Anomaly Detection)": "âœ… Active",
        "TAA (Triage & Analysis)": "âœ… Active", 
        "CLA (Continuous Learning)": "âœ… Active",
        "CRA (Containment Response)": "âš ï¸ Standby"
    }
    
    col1, col2 = st.columns(2)
    
    with col1:
        for agent, status in list(workflow_status.items())[:2]:
            st.markdown(f"**{agent}:** {status}")
    
    with col2:
        for agent, status in list(workflow_status.items())[2:]:
            st.markdown(f"**{agent}:** {status}")
    
    # Performance Metrics
    st.header("ğŸ“ˆ Performance Metrics")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("âš¡ Avg Response Time", "3.2s", "TAA Flash 2.5")

    with col2:
        accuracy = ada_status.get('accuracy', 0) if ada_status else 0
        st.metric("ğŸ¯ System Accuracy", f"{accuracy:.1%}" if accuracy > 0 else "No feedback yet")

    with col3:
        total_alerts = len(df) if not df.empty else 0
        st.metric("ğŸ“Š Alerts (24h)", total_alerts)

    with col4:
        detection_rate = len(df[df['classification'] == 'anomaly']) / max(len(df), 1) * 100 if not df.empty else 0
        st.metric("ğŸ” Detection Rate", f"{detection_rate:.1f}%")

    # Accuracy Trend (if we have historical data)
    st.subheader("ğŸ“ˆ Accuracy Trend (7 days)")

    try:
        client = bigquery.Client(project="chronicle-dev-2be9")
        trend_query = """
        SELECT
            DATE(timestamp) as date,
            AVG(CASE WHEN is_true_positive = true THEN 1.0 ELSE 0.0 END) as accuracy,
            COUNT(*) as feedback_count
        FROM `chronicle-dev-2be9.soc_data.feedback`
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
        GROUP BY DATE(timestamp)
        ORDER BY date
        """

        trend_df = client.query(trend_query).to_dataframe()

        if not trend_df.empty:
            fig = px.line(
                trend_df,
                x='date',
                y='accuracy',
                title="Accuracy Trend Over Time",
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No historical accuracy data available yet")

    except Exception as e:
        st.warning(f"Could not load accuracy trend: {e}")

    # Advanced Feedback Controls
    st.subheader("ğŸ›ï¸ Advanced Feedback Controls")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ”„ Generate Sophisticated Feedback", type="primary"):
            try:
                # Import and run the advanced feedback monitor
                import subprocess
                result = subprocess.run([
                    "python3", "/home/app/advanced_feedback_monitor.py"
                ], capture_output=True, text=True, timeout=60)

                if result.returncode == 0:
                    st.success("âœ… Sophisticated feedback generated successfully!")
                    st.code(result.stdout[-500:])  # Show last 500 chars
                else:
                    st.error("âŒ Error generating feedback")
                    st.code(result.stderr[-500:])

            except Exception as e:
                st.error(f"Error running feedback generation: {e}")

    with col2:
        if st.button("ğŸ“Š Refresh Accuracy Metrics"):
            st.rerun()
    
    # Footer
    st.markdown("---")
    st.markdown(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.markdown("ğŸ›¡ï¸ Enhanced SOC with Google Flash 2.5 TAA Integration")

if __name__ == "__main__":
    main()
